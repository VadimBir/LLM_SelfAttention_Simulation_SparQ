Current pid is 641339
Config:	 Head_dim 64	 Seq_len 2048	 Num_heads 8	 Batch_size 1
Intel(R) Xeon(R) CPU E5-2670 v3 @ 2.30GHz (1 threads)
	K: torch.Size([1, 8, 2048, 64]) V: torch.Size([1, 8, 2048, 64]) Q: torch.Size([1, 8, 2048, 64])
PIN_attn instead of attn
Transformed Layer:  1 PINSTART:  2 PINEND:  1
	Duration List: [6125.87939453125]
	Transformer: 6125.87939453125 Avg Per Layer: 6125.87939453125
_GLOBAL__sub_I_cShared_PinFlags.cpp----------------------------------------- 0 	 1
_GLOBAL__sub_I_cShared_PinFlags.cpp----------------------------------------- 1319976598 	 0
FLAG_Instr_Captured:1319976598:Of: 1319976598
