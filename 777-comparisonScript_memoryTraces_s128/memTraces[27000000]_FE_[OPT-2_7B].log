Current pid is 2103960
Config:	 Head_dim 80	 Seq_len 128	 Num_heads 32	 Batch_size 1
Intel(R) Xeon(R) CPU E5-2670 v3 @ 2.30GHz (1 threads)
	K: torch.Size([1, 32, 128, 80]) V: torch.Size([1, 32, 128, 80]) Q: torch.Size([1, 32, 128, 80])
PIN_attn instead of attn
Transformed Layer:  1 PINSTART:  2 PINEND:  1
	Duration List: [23.91836166381836]
	Transformer: 23.91836166381836 Avg Per Layer: 23.91836166381836
_GLOBAL__sub_I_cShared_PinFlags.cpp----------------------------------------- 0 	 1
_GLOBAL__sub_I_cShared_PinFlags.cpp----------------------------------------- 27337267 	 0
FLAG_Instr_Captured:27337267:Of: 27337267
FLAG_Instr_Captured:0:Of: 0
