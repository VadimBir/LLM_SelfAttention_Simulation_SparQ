{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "# Copyright (c) 2024 Graphcore Ltd. All rights reserved.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES 3\n",
    "\n",
    "from functools import partial\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import *\n",
    "\n",
    "from sparq_benchmark import benchmark_call, gather\n",
    "import gather_matmul as G\n",
    "\n",
    "sns.set_context(\"notebook\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "def reference_gather_inner_bmv(a: Tensor, b: Tensor, i: Tensor) -> Tensor:\n",
    "    return gather(a, 2, i[:, None, :]) @ gather(b, 1, i[:, :, None])\n",
    "\n",
    "def reference_slice_inner_bmv(a: Tensor, b: Tensor, i: Tensor) -> Tensor:\n",
    "    return a[:, :, : i.shape[1]] @ b[:, : i.shape[1], :]\n",
    "\n",
    "def run_benchmark(g: int, k_pre: int, k: int, n: int, dtype: str,\n",
    "                  method: str, transpose_B: bool, chunk: Optional[int]) -> Dict[str, Any]:\n",
    "    device, dtype_ = torch.device(\"cuda\"), getattr(torch, dtype)\n",
    "    config = dict(\n",
    "        g=g, k_pre=k_pre, k=k, n=n, dtype=dtype,\n",
    "        method=method, transpose_B=transpose_B, chunk=chunk,\n",
    "    )\n",
    "    try:\n",
    "        A = torch.randn(g, 1, k_pre, device=device, dtype=dtype_)\n",
    "        B = torch.randn(g, k_pre, n, device=device, dtype=dtype_)\n",
    "        if transpose_B:\n",
    "            B = B.transpose(-1, -2).contiguous().transpose(-1, -2)\n",
    "        I = torch.randint(0, k_pre, (g, k), device=device)\n",
    "        method_fn = dict(\n",
    "            torch=partial(reference_gather_inner_bmv, A, B, I),\n",
    "            slice=partial(reference_slice_inner_bmv, A, B, I),\n",
    "            custom=partial(G.gather_inner_bmv, A, B, I, chunk=chunk),\n",
    "        )[method]\n",
    "        times = benchmark_call(\n",
    "            method_fn, reps=400, warmup=40, device=device, pre_fn=lambda: torch.randint(0, k_pre, I.shape, out=I)\n",
    "        )\n",
    "        return dict(\n",
    "            **config, time=float(times.mean()), time_stderr=float(times.std() / len(times)**.5),\n",
    "            device=torch.cuda.get_device_name(),\n",
    "        )\n",
    "    except Exception as error:\n",
    "        print(f\"Failed config {config} {error}\", file=sys.stderr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "torch.seed()\n",
    "\n",
    "# Sweep around SparQ's approximate QK matmul\n",
    "df = pd.DataFrame.from_dict(filter(None, [\n",
    "    run_benchmark(g=g, k_pre=128, k=k, n=n, dtype=\"float16\",\n",
    "                  method=method, transpose_B=False, chunk=chunk)\n",
    "    for g in [256, 1024, 4096]\n",
    "    for k in [16, 32, 64]\n",
    "    for n in [1024, 4096, 16384]\n",
    "    for method in [\"torch\", \"slice\", \"custom\"]\n",
    "    for chunk in (map(int, 2**torch.arange(0, 11)) if method == \"custom\" else [None])\n",
    "    if not (g >= 2048 and n >= 16384)  # unrecoverable error\n",
    "]))\n",
    "\n",
    "def bytes_transferred(s: pd.Series) -> float:\n",
    "    bytes_per_param = dict(float16=2, float32=4)[s[\"dtype\"]]\n",
    "    return s.g * (2 * s.k + s.k * s.n + s.n) * bytes_per_param\n",
    "\n",
    "df[\"bytes_transferred\"] = df.apply(bytes_transferred, axis=1)\n",
    "df[\"effective_bandwidth\"] = df.bytes_transferred / df.time\n",
    "df.to_json(\"../out/gather_matmul_benchmark/gather_inner_bmv.json\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "device_name, = df.device.unique()\n",
    "expected_memory_bandwidth = {  # B/s\n",
    "    \"NVIDIA A10G\": 600e9,\n",
    "    \"NVIDIA A100-SXM4-40GB\": 1600e9,\n",
    "}[device_name]\n",
    "print(device_name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A good default `chunk=256`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "best = (\n",
    "    df.pipe(lambda d: d[d.method == \"custom\"])\n",
    "    .groupby([\"g\", \"k\", \"n\"])\n",
    "        .apply(lambda s: s.iloc[s.effective_bandwidth.argmax()][[\"bytes_transferred\", \"chunk\", \"effective_bandwidth\"]])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Best chunk size:\")\n",
    "display(best.pivot_table(index=[\"g\"], columns=[\"k\", \"n\"], values=\"chunk\")\n",
    "        .style.format(lambda x: \"\" if pd.isna(x) else f\"{x:.0f}\"))\n",
    "\n",
    "print(\"Achieved bandwidth:\")\n",
    "display(best.pivot_table(index=[\"g\"], columns=[\"k\", \"n\"], values=\"effective_bandwidth\")\n",
    "        .style\n",
    "        .format(lambda x: \"\" if pd.isna(x) else f\"{x/1e9:.0f}\")\n",
    "        .background_gradient(\"flare_r\", vmin=0, vmax=expected_memory_bandwidth))\n",
    "\n",
    "print(\"Best versus chunk=256 achieved bandwidth:\")\n",
    "display(df.pipe(lambda d: d[d.method == \"custom\"])\n",
    "        .groupby([\"g\", \"k\", \"n\"])\n",
    "            .apply(lambda s: s.effective_bandwidth.iloc[s.effective_bandwidth.argmax()] / s.effective_bandwidth[s.chunk==256])\n",
    "        .to_frame(\"ratio\")\n",
    "        .reset_index()\n",
    "        .pivot_table(index=[\"g\"], columns=[\"k\", \"n\"], values=\"ratio\")\n",
    "        .style\n",
    "        .format(lambda x: \"\" if pd.isna(x) else f\"{x:.2f}\")\n",
    "        .background_gradient(\"flare_r\", vmin=1, vmax=1.2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "g, k, n = 1024, 16, 4096\n",
    "d = df.pipe(lambda d: d[(d.g == g) & (d.k == k) & (d.n == n)])\n",
    "ax = plt.gca()\n",
    "colors = iter(sns.color_palette())\n",
    "ax.scatter(d.chunk, d.effective_bandwidth, color=next(colors), label=\"Custom\")\n",
    "ax.hlines(expected_memory_bandwidth, *ax.get_xlim(), \"k\", \"--\", label=\"Theoretical Max\")\n",
    "for method in [\"torch\", \"slice\"]:\n",
    "    ax.hlines(d[d.method==method].effective_bandwidth, *ax.get_xlim(), next(colors), label=method.capitalize())\n",
    "ax.set_xscale(\"log\", base=2)\n",
    "ax.set_yscale(\"log\", base=10)\n",
    "ax.xaxis.set_major_formatter(\"{x:.0f}\")\n",
    "ax.set_xlabel(\"n-chunk size\")\n",
    "ax.set_title(f\"Gather-inner matmul performance\\n$({g} \\\\times 1 \\\\times 128[{k}]) \\;@\\; ({g} \\\\times 128[{k}] \\\\times {n})$\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1.05, 0.5), frameon=False)\n",
    "ax.yaxis.set_major_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.yaxis.set_minor_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.tick_params(axis=\"y\", which=\"minor\", labelsize=10)\n",
    "sns.despine(ax=ax)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Performance is mainly explained by bytes transferred, but `k` has some effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "ax = sns.scatterplot(data=df[df.method!=\"custom\"], y=\"effective_bandwidth\", x=\"bytes_transferred\", style=\"method\",\n",
    "                     color=\"k\", edgecolor=None, markers=dict(torch=\"+\", slice=\"x\"))\n",
    "sns.scatterplot(data=best, y=\"effective_bandwidth\", x=\"bytes_transferred\", hue=\"k\", hue_norm=matplotlib.colors.LogNorm(),\n",
    "                palette=\"flare\", edgecolor=None)\n",
    "ax.set_xscale(\"log\", base=2)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Effective bandwidth /GB/s\")\n",
    "ax.set_xlabel(\"Bytes transferred per call /MiB\")\n",
    "ax.set_title(f\"Gather-inner matmul performance (for best chunk size)\\n$(g \\\\times 1 \\\\times 128[k]) \\;@\\; (g \\\\times 128[k] \\\\times n)$\")\n",
    "ax.yaxis.set_minor_formatter(lambda x, _: f\"{x/1e9:.0f}\")\n",
    "ax.yaxis.set_major_formatter(lambda x, _: f\"{x/1e9:.0f}\")\n",
    "ax.xaxis.set_major_formatter(lambda x, _: f\"{x/2**20:.0f}\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels = [f\"k={label}\" if i >= 2 else label for i, label in enumerate(labels)]\n",
    "ax.legend(handles, labels, frameon=False, bbox_to_anchor=(1, 0.5), loc=\"center left\")\n",
    "sns.despine(ax=ax)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump some compiled kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "k = 16\n",
    "for chunk in [1, 16, 512]:\n",
    "    kernel_cache, = G._kernel_gather_inner_bmv.cache.values()\n",
    "    selected_cache, = (cache for key, cache in kernel_cache.items() if key[2] == (k, chunk, True))\n",
    "    Path(f\"../out/gather_matmul_benchmark/gather_inner_bmv_k={k}_chunk={chunk}.s\").write_text(selected_cache.asm[\"ptx\"])"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
