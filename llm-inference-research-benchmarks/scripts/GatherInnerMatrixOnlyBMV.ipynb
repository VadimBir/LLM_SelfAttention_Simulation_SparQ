{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "# Copyright (c) 2024 Graphcore Ltd. All rights reserved.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES 3\n",
    "\n",
    "from functools import partial\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import *\n",
    "\n",
    "from sparq_benchmark import benchmark_call, gather\n",
    "import gather_matmul as G\n",
    "\n",
    "sns.set_context(\"notebook\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def reference_gather_inner_bmv(a: Tensor, b: Tensor, i: Tensor) -> Tensor:\n",
    "    return a @ gather(b, 1, i[:, :, None])\n",
    "\n",
    "def reference_slice_inner_bmv(a: Tensor, b: Tensor, i: Tensor) -> Tensor:\n",
    "    return a @ b[:, : i.shape[1], :]\n",
    "\n",
    "def run_benchmark(g: int, k_pre: int, k: int, n: int, dtype: str,\n",
    "                  method: str, transpose_B: bool, chunk: Optional[int]) -> Dict[str, Any]:\n",
    "    device, dtype_ = torch.device(\"cuda\"), getattr(torch, dtype)\n",
    "    config = dict(\n",
    "        g=g, k_pre=k_pre, k=k, n=n, dtype=dtype,\n",
    "        method=method, transpose_B=transpose_B, chunk=chunk,\n",
    "    )\n",
    "    try:\n",
    "        A = torch.randn(g, 1, k, device=device, dtype=dtype_)\n",
    "        B = torch.randn(g, k_pre, n, device=device, dtype=dtype_)\n",
    "        if transpose_B:\n",
    "            B = B.transpose(-1, -2).contiguous().transpose(-1, -2)\n",
    "        I = torch.randint(0, k_pre, (g, k), device=device)\n",
    "        method_fn = dict(\n",
    "            torch=partial(reference_gather_inner_bmv, A, B, I),\n",
    "            slice=partial(reference_slice_inner_bmv, A, B, I),\n",
    "            custom=partial(G.gather_inner_matrix_only_bmv, A, B, I, chunk=chunk),\n",
    "        )[method]\n",
    "        times = benchmark_call(\n",
    "            method_fn, reps=100, warmup=10, device=device, pre_fn=lambda: torch.randint(0, k_pre, I.shape, out=I)\n",
    "        )\n",
    "        return dict(\n",
    "            **config, time=float(times.mean()), time_stderr=float(times.std() / len(times)**.5),\n",
    "            device=torch.cuda.get_device_name(),\n",
    "        )\n",
    "    except Exception as error:\n",
    "        print(f\"Failed config {config} {error}\", file=sys.stderr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "torch.seed()\n",
    "\n",
    "# Sweep around SparQ's final KV matmul\n",
    "df = pd.DataFrame.from_dict(filter(None, [\n",
    "    run_benchmark(g=g, k_pre=k_pre, k=k, n=128, dtype=\"float16\",\n",
    "                  method=method, transpose_B=False, chunk=chunk)\n",
    "    for g in [256, 1024, 4096]\n",
    "    for k_pre in [1024, 4096, 16384]\n",
    "    for k in [64, 128, 256, 512]\n",
    "    for method in [\"torch\", \"slice\", \"custom\"]\n",
    "    for chunk in (map(int, 2**torch.arange(0, 8)) if method == \"custom\" else [None])\n",
    "    if not (g >= 2048 and k_pre >= 16384)  # unrecoverable error\n",
    "]))\n",
    "\n",
    "def bytes_transferred(s: pd.Series) -> float:\n",
    "    bytes_per_param = dict(float16=2, float32=4)[s[\"dtype\"]]\n",
    "    return s.g * (2 * s.k + s.k * s.n + s.n) * bytes_per_param\n",
    "\n",
    "df[\"bytes_transferred\"] = df.apply(bytes_transferred, axis=1)\n",
    "df[\"effective_bandwidth\"] = df.bytes_transferred / df.time\n",
    "df.to_json(\"../out/gather_matmul_benchmark/gather_inner_matrix_only_bmv.json\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "device_name, = df.device.unique()\n",
    "expected_memory_bandwidth = {  # B/s\n",
    "    \"NVIDIA A10G\": 600e9,\n",
    "    \"NVIDIA A100-SXM4-40GB\": 1600e9,\n",
    "}[device_name]\n",
    "print(device_name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A good default `chunk=min(64, 8192//k)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "best = (\n",
    "    df.pipe(lambda d: d[d.method == \"custom\"])\n",
    "    .groupby([\"g\", \"k_pre\", \"k\"])\n",
    "        .apply(lambda s: s.iloc[s.effective_bandwidth.argmax()][[\"bytes_transferred\", \"chunk\", \"effective_bandwidth\"]])\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Best chunk size:\")\n",
    "display(best.pivot_table(index=[\"g\"], columns=[\"k_pre\", \"k\"], values=\"chunk\")\n",
    "        .style.format(lambda x: \"\" if pd.isna(x) else f\"{x:.0f}\"))\n",
    "\n",
    "print(\"Achieved bandwidth:\")\n",
    "display(best.pivot_table(index=[\"g\"], columns=[\"k_pre\", \"k\"], values=\"effective_bandwidth\")\n",
    "        .style\n",
    "        .format(lambda x: \"\" if pd.isna(x) else f\"{x/1e9:.0f}\")\n",
    "        .background_gradient(\"flare_r\", vmin=0, vmax=expected_memory_bandwidth))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "g, k_pre, k = 1024, 4096, 64\n",
    "d = df.pipe(lambda d: d[(d.g == g) & (d.k_pre == k_pre) & (d.k == k)])\n",
    "ax = plt.gca()\n",
    "colors = iter(sns.color_palette())\n",
    "ax.scatter(d.chunk, d.effective_bandwidth, color=next(colors), label=\"Custom\")\n",
    "ax.hlines(expected_memory_bandwidth, *ax.get_xlim(), \"k\", \"--\", label=\"Theoretical Max\")\n",
    "for method in [\"torch\", \"slice\"]:\n",
    "    ax.hlines(d[d.method==method].effective_bandwidth, *ax.get_xlim(), next(colors), label=method.capitalize())\n",
    "ax.set_xscale(\"log\", base=2)\n",
    "ax.set_yscale(\"log\", base=10)\n",
    "ax.xaxis.set_major_formatter(\"{x:.0f}\")\n",
    "ax.set_xlabel(\"n-chunk size\")\n",
    "ax.set_title(f\"Gather-inner matmul performance\\n$({g} \\\\times 1 \\\\times {k_pre}[{k}]) \\;@\\; ({g} \\\\times {k_pre}[{k}] \\\\times 128)$\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1.05, 0.5), frameon=False)\n",
    "ax.yaxis.set_major_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.yaxis.set_minor_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.tick_params(axis=\"y\", which=\"minor\", labelsize=10)\n",
    "sns.despine(ax=ax)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The implementation has room for improvement; performance depends on {`g`, `k_pre`, `k`}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "ax = sns.scatterplot(data=df[df.method!=\"custom\"], y=\"effective_bandwidth\", x=\"bytes_transferred\", style=\"method\",\n",
    "                     color=\"k\", edgecolor=None, markers=dict(torch=\"+\", slice=\"x\"))\n",
    "sns.scatterplot(data=best, y=\"effective_bandwidth\", x=\"bytes_transferred\", hue=\"g\", style=\"k_pre\", hue_norm=matplotlib.colors.LogNorm(),\n",
    "                palette=\"flare\", edgecolor=None)\n",
    "ax.set_xscale(\"log\", base=2)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Effective bandwidth\")\n",
    "ax.set_xlabel(\"Bytes transferred per call\")\n",
    "ax.set_title(f\"Gather-inner matmul performance (for best chunk size)\\n$(g \\\\times 1 \\\\times k_{{pre}}[k]) \\;@\\; (g \\\\times k_{{pre}}[k] \\\\times 128)$\")\n",
    "ax.yaxis.set_major_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.yaxis.set_minor_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.yaxis.set_major_formatter(lambda x, _: f\"{x/1e9:.0f} GB/s\")\n",
    "ax.xaxis.set_major_formatter(lambda x, _: f\"{x/2**20:.0f} MiB\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, frameon=False, bbox_to_anchor=(1, 0.5), loc=\"center left\")\n",
    "sns.despine(ax=ax)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
