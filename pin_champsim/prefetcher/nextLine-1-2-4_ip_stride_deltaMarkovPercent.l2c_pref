//
// From Data Prefetching Championship Simulator 2
// Seth Pugsley, seth.h.pugsley@intel.com
//

/*

  This file describes an Instruction Pointer-based (Program Counter-based) stride prefetcher.  
  The prefetcher detects stride patterns coming from the same IP, and then 
  prefetches additional cache lines.

  Prefetches are issued into the L2 or LLC depending on L2 MSHR occupancy.

 */

#define FORCEALLHITS false

// PREFETCHER CONSTANTS ----------------------------------------------------------------------------------------------

// L2 Max PF Allowed
#define MAX_PF_L2 8

// MARKOV
#define MK_SIZE 512 
#define MK_TMAX 8
#define MK_TMIN 0
#define PTHRESH 30

// IP STRIDE
#define IP_TRACKER_COUNT 1024
#define PREFETCH_DEGREE 15


// END PREFETCHER CONSTANTS ----------------------------------------------------------------------------------------------


#include "cache.h"

#include <map>
#include <unordered_map>
#include <vector>
#include <utility>
#include <algorithm>
#include <numeric>

#include <list>
#include <cstdint>



uint64_t NUM_CACHELINES = 0;

std::unordered_map<int64_t, std::unordered_map<int64_t, int>> markov_table;
//const int MARKOV_LRU_SIZE = 1 + 256; // 8192 16384 32768
using IteratorType = std::unordered_map<int64_t, std::unordered_map<int64_t, int>>::iterator;
//std::array<std::unordered_map<int64_t, int>::iterator, MARKOV_LRU_SIZE> markov_LRU{};
int markov_LRU_front = 0;
//const int MAX_PREDICTIONS = 10;
//const int MARKOV_PREDICTION_PERCENTTHRESHOLD = 5;//16 max predictions if each is 6.25% // 25 may have max 4 predictions, 50 may have max 2 predictions and 75 may have max 1 prediction but those are unlikely. 

std::vector<int> popular_prefetch_offset = {};

uint64_t pre_previous_addr = 0;
uint64_t previous_addr = 0;
uint64_t pf_addr = 0;
int64_t cnt = 0;


// MARKOV PREFETCHER CLASS ----------------------------------------------------------------------------------------------

#include <map>
#include <unordered_map>
#include <vector>
#include <utility>
#include <algorithm>
// #include <array>
// #include <iostream>
#include <numeric>

int wType = 0;
class Delta_Markov_Delta {

public:
    static const int MARKOV_LRU_SIZE = MK_SIZE;
    static const int MAX_PREDICTIONS = 9999;
    static constexpr double MARKOV_PREDICTION_PERCENTTHRESHOLD = 0;

    // filter outliers
    static const int32_t OUTLIERS_THRESHOLD_Max = MK_TMAX; 
    static const int32_t OUTLIERS_THRESHOLD_Min = MK_TMIN;
    Delta_Markov_Delta() : markov_LRU_front(0), pre_previous_addr(0), previous_addr(0), pf_addr(0), pre_ip(0) {}

    std::vector<int64_t> operate(uint64_t addr, uint64_t ip, uint8_t cache_hit, uint8_t type) {
        // USING MARKOV PREFETCHER ---------------------------------------------------------------------------------------------- MARKOV START

        // markov preprocessing
        int64_t key_delta = 0;
        int64_t val_delta = 0;

        addr = addr ;
        //addr = addr ;
        if (pre_previous_addr != 0) {
            key_delta = (int64_t)(pre_previous_addr) - (int64_t)(previous_addr);
            val_delta = (int64_t)(previous_addr) - (int64_t)(addr);
        }

        IteratorType key_it;
        std::unordered_map<int64_t, int>::iterator val_it;

        // filter out val_delta that were part of popular_prefetch_offset
        
        // markov table update
        if (pre_previous_addr != 0) {
            //int64_t final_hash_value = combine_hashes(pre_ip, key_delta);
            //final_hash_value = combine_hashes(wType,final_hash_value);

            key_delta = 0;
            // int64_t final_hash_value = combine_hashes(pre_ip, key_delta);
            // key_delta = final_hash_value;
            
            if ((std::abs(val_delta) >= OUTLIERS_THRESHOLD_Min && std::abs(val_delta) <= OUTLIERS_THRESHOLD_Max)){
            //if (std::abs(val_delta) >= -OUTLIERS_THRESHOLD_Max && std::abs(val_delta) <= OUTLIERS_THRESHOLD_Max) {
                // if NOT in popular offset, add to markov table
                if (std::find(popular_prefetch_offset.begin(), popular_prefetch_offset.end(), val_delta) == popular_prefetch_offset.end()) {
                    markov_table[key_delta][val_delta]++;
                }
            }

             //       markov_table[key_delta][val_delta]++;


            key_it = markov_table.find(key_delta);
            if ((std::abs(val_delta) >= OUTLIERS_THRESHOLD_Min && std::abs(val_delta) <= OUTLIERS_THRESHOLD_Max)) {

            //if (std::abs(val_delta) >= -OUTLIERS_THRESHOLD_Max && std::abs(val_delta) <= OUTLIERS_THRESHOLD_Max) {
                val_it = key_it->second.find(val_delta);
            }
        }
        // get Markov delta predictions and return vector<int64_t> top_predictions
        std::vector<int64_t> pf_topP = markov_prefetcher(addr, ip, key_it, val_it);

        // update previous address and previous IP
        pre_previous_addr = previous_addr;
        previous_addr = addr;
        pre_ip = ip;

        
        return pf_topP;
        }
    
private:

    // Markov table and LRU
    std::unordered_map<int64_t, std::unordered_map<int64_t, int>> markov_table;
    
    using IteratorType = std::unordered_map<int64_t, std::unordered_map<int64_t, int>>::iterator;
    std::array<std::unordered_map<int64_t, int>::iterator, MARKOV_LRU_SIZE> markov_LRU{};
    int markov_LRU_front;



    // Address tracking
    uint64_t pre_previous_addr;
    uint64_t previous_addr;
    uint64_t pf_addr;
    uint64_t pre_ip;
    //int64_t cnt = 0;


    // Helper methods
    int64_t combine_hashes(int64_t pre_key_delta, int64_t key_delta) {
        std::hash<int64_t> hasher;
        int64_t hash1 = hasher(pre_key_delta);
        int64_t hash2 = hasher(key_delta);

        return hash1 ^ (hash2 << 1);
    }

    std::unordered_map<int64_t, int>::iterator markov_evict_lru() {
        std::unordered_map<int64_t, int>::iterator val_it = markov_LRU[0];
        for (int i = 1; i < markov_LRU_front; i++) {
            markov_LRU[i - 1] = markov_LRU[i];
        }
        return val_it;
    }

    void markov_update_lru(int index) {
        auto tmpVal = markov_LRU[index];
        for (int i = 0; i < markov_LRU_front; i++) {
            if (i < index) {
                continue;
            }
            markov_LRU[i] = markov_LRU[i + 1];
        }

        markov_LRU[markov_LRU_front - 1] = tmpVal;
    }

    std::vector<int64_t> markov_prefetcher(uint64_t addr, uint64_t ip, IteratorType key_it, std::unordered_map<int64_t, int>::iterator val_it) {
        std::vector<int64_t> top_predictions;
        //int64_t doubleDeltaKey = combine_hashes(ip, (int64_t)previous_addr-(int64_t)addr);
        //doubleDeltaKey = combine_hashes(wType, doubleDeltaKey);
        // int64_t doubleDeltaKey = combine_hashes(ip, static_cast<int64_t>(previous_addr) - static_cast<int64_t>(addr));
        // auto it = markov_table.find(doubleDeltaKey);

        auto it = markov_table.find((int64_t)previous_addr-(int64_t)addr);

        if (it != markov_table.end()) {
            //cout << "Found in Markov Table" << endl;
            auto &next_blocks = it->second;
            std::vector<std::pair<int64_t, int>> predictions(next_blocks.begin(), next_blocks.end());
            std::sort(predictions.begin(), predictions.end(),
                      [](std::pair<int64_t, int> &a, std::pair<int64_t, int> &b) {
                          return a.second > b.second;
                      });
            int total_count = std::accumulate(predictions.begin(), predictions.end(), 0,
                [](int sum, std::pair<int64_t, int>& p) {
                    return sum + p.second;
                });
            for (auto &prediction : predictions) {
                //if (top_predictions.size() >= MAX_PREDICTIONS) break;
                if ((static_cast<double>(prediction.second) * 100 / total_count) >= MARKOV_PREDICTION_PERCENTTHRESHOLD) {
                    pf_addr = prediction.first;
                    top_predictions.push_back(pf_addr);
                    //std::cout << "Markov Prediction: " << prediction.second << " total: " <<  total_count << " percent: " << (((double)prediction.second)*100/total_count) << std::endl;
                } else {
                    break;
                }
            }
        }
        
        auto lru_it = std::find(markov_LRU.begin(), markov_LRU.end(), val_it);
        if (lru_it != markov_LRU.end()) {
            int index = static_cast<int>(lru_it - markov_LRU.begin());
            markov_update_lru(index);
        } else {
            if (markov_LRU_front != MARKOV_LRU_SIZE - 1) {
                markov_LRU[markov_LRU_front] = val_it;
                markov_LRU_front++;
            } else {
                auto toDel = markov_evict_lru();
                for (auto &outer_pair : markov_table) {
                    auto &inner_map = outer_pair.second;
                    for (auto it_inner = inner_map.begin(); it_inner != inner_map.end();) {
                        if (it_inner == toDel) {
                            it_inner = inner_map.erase(it_inner);
                            break;
                        } else {
                            ++it_inner;
                        }
                    }
                }
                for (auto it_outer = markov_table.begin(); it_outer != markov_table.end();) {
                    if (it_outer->second.empty()) {
                        it_outer = markov_table.erase(it_outer);
                    } else {
                        ++it_outer;
                    }
                }

                markov_LRU[markov_LRU_front - 1] = val_it;
            }
        }
        return top_predictions;
    }    
};

// END MARKOV PREFETCHER CLASS ----------------------------------------------------------------------------------------------


class IP_TRACKER {
  public:
    // the IP we're tracking
    uint64_t ip;

    // the last address accessed by this IP
    uint64_t last_cl_addr;

    // the stride between the last two addresses accessed by this IP
    int64_t last_stride;

    // use LRU to evict old IP trackers
    uint32_t lru;

    IP_TRACKER () {
        ip = 0;
        last_cl_addr = 0;
        last_stride = 0;
        lru = 0;
    };
};

IP_TRACKER trackers[IP_TRACKER_COUNT];

void CACHE::l2c_prefetcher_initialize() 
{
    cout << "CPU " << cpu << " L2C IP-based stride prefetcher" << endl;
    for (int i=0; i<IP_TRACKER_COUNT; i++)
        trackers[i].lru = i;

}


// markov prefetcher object
Delta_Markov_Delta markov_prefetcher;

uint32_t CACHE::l2c_prefetcher_operate(uint64_t addr, uint64_t ip, uint8_t cache_hit, uint8_t type, uint32_t metadata_in)
{
    if(NUM_CACHELINES == 0){
        uint64_t cache_size = (L2C_SET*L2C_WAY*BLOCK_SIZE)/1024;
        cout << "CPU " << cpu << " L2C next line prefetcher initialized" << endl;
        cout << "\n\nCache Size: " << cache_size << endl;
        cout << "number of cache lines: " << L2C_SET*L2C_WAY << endl;
        NUM_CACHELINES = L2C_SET*L2C_WAY;
    }

    
    // USING NXT LINE PREFETCHER ---------------------------------------------------------------------------------------------- NXT LINE START
    //    for (int offset : popular_prefetch_offset) {
    //         pf_addr = ((addr >> LOG2_BLOCK_SIZE) + offset) << LOG2_BLOCK_SIZE;
    //         prefetch_line(ip, addr, pf_addr, FILL_L2, 0);

    //    }
    // END OF NXT LINE PREFETCHER ---------------------------------------------------------------------------------------------- NXT LINE END
    


    // IP STRIDE PREFETCHER ---------------------------------------------------------------------------------------------- IP STRIDE START
    // check for a tracker hit
    uint64_t cl_addr = addr >> LOG2_BLOCK_SIZE;

    int index = -1;
    for (index=0; index<IP_TRACKER_COUNT; index++) {
        if (trackers[index].ip == ip)
            break;
    }
    if (index == IP_TRACKER_COUNT) {

        for (index=0; index<IP_TRACKER_COUNT; index++) {
            if (trackers[index].lru == (IP_TRACKER_COUNT-1))
                break;
        }

        trackers[index].ip = ip;
        trackers[index].last_cl_addr = cl_addr;
        trackers[index].last_stride = 0;

        //cout << "[IP_STRIDE] MISS index: " << index << " lru: " << trackers[index].lru << " ip: " << hex << ip << " cl_addr: " << cl_addr << dec << endl;

        for (int i=0; i<IP_TRACKER_COUNT; i++) {
            if (trackers[i].lru < trackers[index].lru)
                trackers[i].lru++;
        }
        trackers[index].lru = 0;

        return metadata_in;
    }

    // sanity check
    // at this point we should know a matching tracker index
    if (index == -1)
        assert(0);

    // calculate the stride between the current address and the last address
    // this bit appears overly complicated because we're calculating
    // differences between unsigned address variables
    int64_t stride = 0;
    if (cl_addr > trackers[index].last_cl_addr)
        stride = cl_addr - trackers[index].last_cl_addr;
    else {
        stride = trackers[index].last_cl_addr - cl_addr;
        stride *= -1;
    }

    //cout << "[IP_STRIDE] HIT  index: " << index << " lru: " << trackers[index].lru << " ip: " << hex << ip << " cl_addr: " << cl_addr << dec << " stride: " << stride << endl;

    // don't do anything if we somehow saw the same address twice in a row
    if (stride == 0)
        return metadata_in;

    // only do any prefetching if there's a pattern of seeing the same
    // stride more than once
    if (stride == trackers[index].last_stride) {

        // do some prefetching
        for (int i=0; i<PREFETCH_DEGREE; i++) {
            uint64_t pf_addr = (cl_addr + (stride*(i+1))) << LOG2_BLOCK_SIZE;

            // only issue a prefetch if the prefetch address is in the same 4 KB page 
            // as the current demand access address
            if ((pf_addr >> LOG2_PAGE_SIZE) != (addr >> LOG2_PAGE_SIZE))
                break;

            // check the MSHR occupancy to decide if we're going to prefetch to the L2 or LLC
            if (MSHR.occupancy < (MSHR.SIZE>>1)){
	            prefetch_line(ip, addr, pf_addr, FILL_L2, 0);
                //GHP_Stride->append(pf_addr >> LOG2_BLOCK_SIZE);
            }
            else{
	            prefetch_line(ip, addr, pf_addr, FILL_LLC, 0);
            }
        

            // if (GHP_Stride->size() > (NUM_CACHELINES*1)) { // does a sliding window of size
            //     GHP_Stride->pop();
            //     prefetchGuessCnt_Stride++;
            // }
            
        }
    }

    trackers[index].last_cl_addr = cl_addr;
    trackers[index].last_stride = stride;

    for (int i=0; i<IP_TRACKER_COUNT; i++) {
        if (trackers[i].lru < trackers[index].lru)
            trackers[i].lru++;
    }
    trackers[index].lru = 0;

    // IP STRIDE PREFETCHER ---------------------------------------------------------------------------------------------- IP STRIDE END

    

    // USING MARKOV PREFETCHER ---------------------------------------------------------------------------------------------- MARKOV START
    
    uint64_t aligned_addr = addr >> LOG2_BLOCK_SIZE;
    std::vector<int64_t> markov_predictions = markov_prefetcher.operate(aligned_addr, ip, cache_hit, type);

    for (auto offset : markov_predictions) {
        pf_addr = ((aligned_addr - offset) << LOG2_BLOCK_SIZE);
        
        // check page 
        if ((pf_addr >> LOG2_PAGE_SIZE) != (addr >> LOG2_PAGE_SIZE))
            continue;
        prefetch_line(ip, addr, pf_addr, FILL_L2, metadata_in);
    }
    // DONE USING MARKOV PREFETCHER ---------------------------------------------------------------------------------------------- DONE MARKOV

    // update the variables for the next iteration
    pre_previous_addr = previous_addr;
    previous_addr = addr;
    cnt++;
    return metadata_in;
}

uint32_t CACHE::l2c_prefetcher_cache_fill(uint64_t addr, uint32_t set, uint32_t way, uint8_t prefetch, uint64_t evicted_addr, uint32_t metadata_in)
{
  return metadata_in;
}

void CACHE::l2c_prefetcher_final_stats()
{
    cout << "CPU " << cpu << " L2C prefetcher final stats" << endl;

}
